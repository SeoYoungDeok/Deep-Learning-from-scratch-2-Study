{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 [게이트가 추가된 RNN]\n",
    "---\n",
    "앞 장의 단순한 RNN은 시계열 데이터에서 시간적으로 멀리 떨어진, 장기 의존 관계를 잘 학습할 수 없다는 문제가 있습니다.  \n",
    "LSTM, GRU 구조는 '게이트<sup>gate</sup>'라는 구조가 더해져 있는데, 이 게이트 덕분에 시계열 데이터의 장기 의존 관계를 학습할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RNN의 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 소실 또는 기울기 폭발\n",
    "---\n",
    "<img src=img/fig6-5.png width='800'>  \n",
    "RNN 계층에서 시간 방향으로 역전파 할 때 전해지는 기울기는 차례로 'tanh', '+', 'MatMul'연산을 통과합니다.\n",
    "이 계층들이 기울기를 어떻게 변화시킬까요?\n",
    "\n",
    "$ y = tanh(x) $일 때의 미분은 $ \\frac{\\partial y}{\\partial x}=1-y^{2} $ 입니다. 이때 $ y = tanh(x) $의 값과 그 미분 값을 각각 그래프로 그리면 다음과 같습니다.  \n",
    "<img src=img/fig6-6.png width='400'>  \n",
    "점선이 $ y = tanh(x) $의 미분입니다. 보다시피 그 값은 1.0 이하이고, x가 0으로부터 멀어질수록 작아집니다.  \n",
    "즉 역전파에서 기울기가 tanh 노드를 지날 때마다 값은 계속 작아진다는 뜻입니다.  \n",
    "\n",
    "다음은 Matmul 노드 입니다.  \n",
    "상류로부터 $ dh $라는 기울기가 흘러옵니다.  \n",
    "이때 MatMul 노드에서의 역전파는 $ dhW_{n}^{T} $라는 행렬 곱으로 기울기를 계산합니다.  \n",
    "그리고 같은 계산을 시계열 데이터의 시간 크기만큼 반복하죠. 그러면 역전파 시 기울기는 MatMul 노드를 지날 때마다 어떻게 변할까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4684068094579303, 3.3357049741610365, 4.783279375373182, 6.279587332087612, 8.080776465019053, 10.251163032292936, 12.936063506609896, 16.276861327786712, 20.45482961834598, 25.688972842084684, 32.25315718048336, 40.48895641683869, 50.8244073070191, 63.79612654485427, 80.07737014308985, 100.5129892205125, 126.16331847536823, 158.35920648258823, 198.7710796761195, 249.495615421267]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165.82723327563536, 46.073751982593116, 39.33717299029768, 15.343673208370237, 13.427630740269848, 7.764749802532891, 5.710756601803507, 3.7195501552126626, 2.5825395665804947, 1.735482186197724, 1.1861180077280082, 0.8036560015488017, 0.5469555307956063, 0.3713955517070608, 0.2524843606451469, 0.17154116983311937, 0.11658374794484584, 0.07922054522299886, 0.0538360964803239, 0.03658396904103571]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 2   # 미니배치 크기\n",
    "H = 3   # 은닉 상태 벡터의 차원 수\n",
    "T = 20  # 시계열 데이터의 길이\n",
    "\n",
    "dh = np.ones((N, H))\n",
    "\n",
    "np.random.seed(3) # 재현할 수 있도록 난수의 시드 고정\n",
    "\n",
    "Wh = np.random.randn(H, H)\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.dot(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N\n",
    "    norm_list.append(norm)\n",
    "\n",
    "print(norm_list)\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.plot(np.arange(len(norm_list)), norm_list)\n",
    "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
    "plt.xlabel('시간 크기(time step)')\n",
    "plt.ylabel('노름(norm)')\n",
    "plt.show()\n",
    "\n",
    "Wh = np.random.randn(H, H) * 0.5\n",
    "\n",
    "norm_list = []\n",
    "for t in range(T):\n",
    "    dh = np.dot(dh, Wh.T)\n",
    "    norm = np.sqrt(np.sum(dh**2)) / N\n",
    "    norm_list.append(norm)\n",
    "\n",
    "print(norm_list)\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.plot(np.arange(len(norm_list)), norm_list)\n",
    "plt.xticks([0, 4, 9, 14, 19], [1, 5, 10, 15, 20])\n",
    "plt.xlabel('시간 크기(time step)')\n",
    "plt.ylabel('노름(norm)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프에서 보듯 기울기의 크기는 시간에 비례해 지수적으로 증가(폭발) 혹은 감소(소실)합니다.  \n",
    "이러한 현상 때문에 장기 의존 관계를 학습할 수 없게 됩니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기울기 폭발 대책\n",
    "---\n",
    "기울기 폭발의 대책으로는 **기울기 클리핑**<sup>gradients clipping</sup>이라는 전통적인 기법이 있습니다.  \n",
    "그 알고리즘을 의사 코드로 쓰면 다음과 같습니다.  \n",
    "\n",
    "$$ \\large{\\mathrm{ if\\  \\lVert \\hat{\\mathbf{g}} \\lVert\\ \\ge\\ threshold}}: $$  \n",
    "$$ \\large{\\mathrm{ \\hat{\\mathbf{g}} = \\frac{threshold}{\\lVert \\hat{\\mathbf{g}} \\lVert}\\hat{\\mathbf{g}}}} $$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dW1 = np.random.rand(3, 3) * 10\n",
    "dW2 = np.random.rand(3, 3) * 10\n",
    "grads = [dW1, dW2]\n",
    "max_norm = 5.0\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 기울기 소실과 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM의 인터페이스\n",
    "---\n",
    "LSTM 계층을 자세히 살펴보기 전에 계산 그래프를 단순화하는 도법을 사용하겠습니다.  \n",
    "<img src=img/fig6-10.png width='800'>  \n",
    "그림에서 $ tanh(h_{t-1}W_{h} + x_{t}W{x} + b) $ 계산을 tanh라는 직사각형 노드 하나로 그렸습니다.  \n",
    "\n",
    "이제 LSTM과 RNN을 비교하는 것부터 시작해보겠습니다.  \n",
    "<img src=img/fig6-11.png width='800'>  \n",
    "그림처럼 LSTM 계층의 인터페이스에는 $c$라는 경로가 있다는 차이가 있습니다.  \n",
    "이 $c$를 **기억 셀**<sup>memory cell</sup>이라 하며, LSTM 전용의 기억 메커니즘입니다.\n",
    "\n",
    "기억 셀의 특징은 데이터를 자기 자신으로만(LSTM 계층 내에서만) 주고받는다는 것입니다.  \n",
    "즉, LSTM 계층 내에서만 연결되고, 다른 계층으로는 출력하지 않습니다.  \n",
    "LSTM의 은닉상태 h는 RNN 계층과 마찬가지로 다른 계층으로(위쪽으로) 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 계층 조립하기\n",
    "---\n",
    "LSTM의 부품을 하나씩 조립하면서, 그 구조를 차분히 알아보겠습니다.  \n",
    "\n",
    "LSTM에는 기억 셀 $c_{t}$가 있습니다. 이 $c_{t}$에는 시각 $t$에서의 LSTM의 기억이 저장돼 있는데  \n",
    "과거로부터 시각 $t$까지에 필요한 모든 정보가 저장돼 있다고 가정합니다. (혹은 그렇게 되도록 학습을 수행합니다.)  \n",
    "그리고 필요한 정보를 모두 간직한 이 기억을 바탕으로, 외부 계층에(그리고 다음 시각의 LSTM에) 은닉 상태 $h_{t}$를 출력합니다.  \n",
    "<img src=img/fig6-12.png width='500'>  \n",
    "그림처럼 현재의 기억 셀 $c_{t}$는 3개의 입력($c_{t-1}, h_{t-1}, x_{t}$)으로부터 '어떤 계산'을 수행하여 구할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output 게이트\n",
    "---\n",
    "이 게이트는 $tanh(c_{t})$의 각 원소에 대해 '그것이 다음 시각의 은닉 상태에 얼마나 중요한가'를 조정합니다.  \n",
    "output 게이트의 열림 상태(다음 몇 %만 흘려보낼까)는 입력 $x_{t}$와 이전 상태 $h_{t-1}$로부터 구합니다.  \n",
    "이때의 계산은 다음과 같습니다. 여기서 사용하는 가중치 매개변수와 편향에는 output의 첫 글자인 $o$를 첨자로 추가합니다.  \n",
    "이후에도 마찬가지로 첨자를 붙여 게이트임을 표시하겠습니다. 한편, 시그모이드 함수는 $\\sigma()$로 표기합니다.  \n",
    "\n",
    "$$ \\large{\\mathrm{ o = \\sigma(x_{t}W^{(o)}_{x} + h_{t-1}W^{(o)}_{h} + b^{(o)}) }} $$  \n",
    "<img src=img/fig6-15.png width='500'>  \n",
    "$\\sigma$의 출력을 $o$라고 하면 $h_t$는 $o$와 $tanh(c_t)$의 곱으로 계산됩니다.  \n",
    "여기서 말하는 '곱'이란 원소별 곱이며, 이것을 **아다마르 곱**<sup>Hadamard product</sup>이라고도 합니다.  \n",
    "아다마르 곱은 기호로 $\\odot$으로 나타내며, 다음과 같은 계산을 수행합니다.  \n",
    "\n",
    "$$ \\large{\\mathrm{ h_{t} = o \\odot tanh(c_{t}) }} $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### forget 게이트\n",
    "---\n",
    "망각은 더 나은 전진을 낳습니다. 우리가 다음에 해야 할 일은 기억 셀에 '무엇을 잊을까'를 명확하게 지시하는 것입니다.  \n",
    "그러면 $c_{t-1}$의 기억 중에서 불필요한 기억을 잊게 해주는 게이트를 추가하고, 이를 **forget 게이트**(망각 게이트)라 부르도록 하겠습니다.  \n",
    "<img src=img/fig6-16.png width='500'>  \n",
    "$$ \\large{\\mathrm{ f = \\sigma(x_{t}W^{(f)}_{x} + h_{t-1}W^{(f)}_{h} + b^{(f)}) }} $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 기억 셀\n",
    "---\n",
    "forget 게이트를 거치면서 이전 시각의 기억 셀로부터 잊어야 할 기억이 삭제되었습니다.  \n",
    "그런데 이 상태로는 기억 셀이 잊는 것밖에 하지 못하겠네요. 그래서 새로 기억해야 할 정보를 기억셀에 추가해야 합니다.  \n",
    "<img src=img/fig6-17.png width='500'>  \n",
    "$$ \\large{\\mathrm{ g = tanh(x_{t}W^{(g)}_{x} + h_{t-1}W^{(g)}_{h} + b^{(g)}) }} $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input 게이트\n",
    "---\n",
    "마지막으로 $g$에 게이트를 하나 추가하겠습니다. 여기에서 새롭게 추가하는 게이트를 **input 게이트**(입력 게이트)라고 하겠습니다.  \n",
    "<img src=img/fig6-18.png width='500'>  \n",
    "input 게이트는 $g$의 각 원소가 새로 추가되는 정보로써의 가치가 얼마나 큰지를 판단합니다.  \n",
    "새 정보를 무비판적으로 수용하는게 아니라, 적절히 취사선택하는 것이 이 게이트의 역할입니다.  \n",
    "다른 관점에서 보면, input 게이트에 의해 가중된 정보가 새로 추가되는 셈입니다.\n",
    "\n",
    "$$ \\large{\\mathrm{ i = \\sigma(x_{t}W^{(i)}_{x} + h_{t-1}W^{(i)}_{h} + b^{(i)}) }} $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM의 기울기 흐름\n",
    "---\n",
    "LSTM의 구조를 살표보았는데, 이것이 어떤 원리로 기울기 소실을 없애주는 걸까요?  \n",
    "그 원리는 기억 셀 $c$의 역전파에 주목하면 보입니다.  \n",
    "<img src=img/fig6-19.png width='800'>  \n",
    "기억 셀의 역전파에서는 '+'와 'x'노드만을 지나게 됩니다.  \n",
    "'+'노드는 상류에서 전해지는 기울기를 그대로 흘릴 뿐입니다. 따라서 기울기의 변화(감소)는 일어나지 않습니다.  \n",
    "\n",
    "그럼 'x'노드가 남는데, 이 노드는 '행렬 곱'이 아닌 '원소별 곱(아다마르 곱)'을 계산합니다.  \n",
    "LSTM의 역전파에서는 '행렬 곱'이 아닌 '원소별 곱'이 이뤄지고, 매 시각 다른 게이트 값을 이용해 원소별 곱을 계산합니다.  \n",
    "이처럼 매번 새로운 게이트 값을 이용하므로 곱셈의 효과가 누적되지 않아 기울기 소실이 일어나지 않는 (혹은 일어나기 어려운) 것입니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LSTM 구현\n",
    "다음은 LSTM에서 수행하는 계산을 정리한 수식들입니다.  \n",
    "$$ \\large{\\mathrm{ f = \\sigma(x_{t}W^{(f)}_{x} + h_{t-1}W^{(f)}_{h} + b^{(f)}) }} $$\n",
    "$$ \\large{\\mathrm{ g = tanh(x_{t}W^{(g)}_{x} + h_{t-1}W^{(g)}_{h} + b^{(g)}) }} $$\n",
    "$$ \\large{\\mathrm{ i = \\sigma(x_{t}W^{(i)}_{x} + h_{t-1}W^{(i)}_{h} + b^{(i)}) }} $$\n",
    "$$ \\large{\\mathrm{ o = \\sigma(x_{t}W^{(o)}_{x} + h_{t-1}W^{(o)}_{h} + b^{(o)}) }} $$\n",
    "\n",
    "$$ \\large{\\mathrm{ c_{t} = f \\odot c_{t-1} + g \\odot i }} $$\n",
    "$$ \\large{\\mathrm{ h_{t} = o \\odot tanh(c_{t}) }} $$  \n",
    "\n",
    "$\\mathrm{f, g, i, o}$는 하나의 식으로 정리해 계산할 수 있습니다.  \n",
    "<img src=img/fig6-20.png width='700'>  \n",
    "4개의 가중치를 하나로 모을 수 있고, 그렇게 하면 원래 개별적으로 총 4번을 수행하던 아핀 변환을 단 1회의 계산으로 끝마칠 수 있습니다.  \n",
    "<img src=img/fig6-21.png width='700'>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Wx: 입력 x에 대한 가중치 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        Wh: 은닉 상태 h에 대한 가장추 매개변수(4개분의 가중치가 담겨 있음)\n",
    "        b: 편향（4개분의 편향이 담겨 있음）\n",
    "        '''\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "\n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "\n",
    "        A = np.dot(x, Wx) + np.dot(h_prev, Wh) + b\n",
    "\n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "\n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "\n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "\n",
    "        self.cache = (x, h_prev, c_prev, i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "    def backward(self, dh_next, dc_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "\n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "\n",
    "        dc_prev = ds * f\n",
    "\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "\n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= (1 - g ** 2)\n",
    "\n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "\n",
    "        dWh = np.dot(h_prev.T, dA)\n",
    "        dWx = np.dot(x.T, dA)\n",
    "        db = dA.sum(axis=0)\n",
    "\n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "\n",
    "        dx = np.dot(dA, Wx.T)\n",
    "        dh_prev = np.dot(dA, Wh.T)\n",
    "\n",
    "        return dx, dh_prev, dc_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time LSTM 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "\n",
    "        self.h, self.c = None, None\n",
    "        self.dh = None\n",
    "        self.stateful = stateful\n",
    "\n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = Wh.shape[0]\n",
    "\n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "\n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n",
    "            hs[:, t, :] = self.h\n",
    "\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        return hs\n",
    "\n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = Wx.shape[0]\n",
    "\n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:, t, :] + dh, dc)\n",
    "            dxs[:, t, :] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "\n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        return dxs\n",
    "\n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LSTM을 사용한 언어 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "언어 모델은 앞 챕터에서 구현한 모델에서 RNN계층이 LSTM계층으로 바뀐것이 유일한 차이점 입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.time_layers import *\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class Rnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=100, hidden_size=100):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        # 가중치 초기화\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeLSTM(lstm_Wx, lstm_Wh, lstm_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layer = self.layers[1]\n",
    "\n",
    "        # 모든 가중치와 기울기를 리스트에 모은다.\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts):\n",
    "        score = self.predict(xs)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.lstm_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 10002.16\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 6[s] | 퍼플렉서티 3107.97\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 12[s] | 퍼플렉서티 1247.82\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 18[s] | 퍼플렉서티 953.86\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 24[s] | 퍼플렉서티 823.77\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 29[s] | 퍼플렉서티 647.83\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 35[s] | 퍼플렉서티 649.79\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 41[s] | 퍼플렉서티 611.09\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 48[s] | 퍼플렉서티 569.41\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 54[s] | 퍼플렉서티 575.60\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 60[s] | 퍼플렉서티 496.31\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 65[s] | 퍼플렉서티 476.26\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 71[s] | 퍼플렉서티 444.85\n",
      "| 에폭 1 |  반복 261 / 1327 | 시간 77[s] | 퍼플렉서티 463.50\n",
      "| 에폭 1 |  반복 281 / 1327 | 시간 83[s] | 퍼플렉서티 453.60\n",
      "| 에폭 1 |  반복 301 / 1327 | 시간 89[s] | 퍼플렉서티 389.02\n",
      "| 에폭 1 |  반복 321 / 1327 | 시간 95[s] | 퍼플렉서티 345.07\n",
      "| 에폭 1 |  반복 341 / 1327 | 시간 101[s] | 퍼플렉서티 394.09\n",
      "| 에폭 1 |  반복 361 / 1327 | 시간 107[s] | 퍼플렉서티 410.31\n",
      "| 에폭 1 |  반복 381 / 1327 | 시간 113[s] | 퍼플렉서티 330.04\n",
      "| 에폭 1 |  반복 401 / 1327 | 시간 118[s] | 퍼플렉서티 352.77\n",
      "| 에폭 1 |  반복 421 / 1327 | 시간 124[s] | 퍼플렉서티 339.21\n",
      "| 에폭 1 |  반복 441 / 1327 | 시간 130[s] | 퍼플렉서티 322.35\n",
      "| 에폭 1 |  반복 461 / 1327 | 시간 136[s] | 퍼플렉서티 321.69\n",
      "| 에폭 1 |  반복 481 / 1327 | 시간 142[s] | 퍼플렉서티 304.71\n",
      "| 에폭 1 |  반복 501 / 1327 | 시간 148[s] | 퍼플렉서티 313.49\n",
      "| 에폭 1 |  반복 521 / 1327 | 시간 155[s] | 퍼플렉서티 303.92\n",
      "| 에폭 1 |  반복 541 / 1327 | 시간 161[s] | 퍼플렉서티 322.50\n",
      "| 에폭 1 |  반복 561 / 1327 | 시간 167[s] | 퍼플렉서티 284.34\n",
      "| 에폭 1 |  반복 581 / 1327 | 시간 173[s] | 퍼플렉서티 256.15\n",
      "| 에폭 1 |  반복 601 / 1327 | 시간 179[s] | 퍼플렉서티 333.39\n",
      "| 에폭 1 |  반복 621 / 1327 | 시간 185[s] | 퍼플렉서티 308.67\n",
      "| 에폭 1 |  반복 641 / 1327 | 시간 191[s] | 퍼플렉서티 282.37\n",
      "| 에폭 1 |  반복 661 / 1327 | 시간 197[s] | 퍼플렉서티 264.87\n",
      "| 에폭 1 |  반복 681 / 1327 | 시간 203[s] | 퍼플렉서티 224.36\n",
      "| 에폭 1 |  반복 701 / 1327 | 시간 209[s] | 퍼플렉서티 249.90\n",
      "| 에폭 1 |  반복 721 / 1327 | 시간 215[s] | 퍼플렉서티 260.12\n",
      "| 에폭 1 |  반복 741 / 1327 | 시간 221[s] | 퍼플렉서티 221.61\n",
      "| 에폭 1 |  반복 761 / 1327 | 시간 226[s] | 퍼플렉서티 231.25\n",
      "| 에폭 1 |  반복 781 / 1327 | 시간 232[s] | 퍼플렉서티 221.04\n",
      "| 에폭 1 |  반복 801 / 1327 | 시간 238[s] | 퍼플렉서티 240.00\n",
      "| 에폭 1 |  반복 821 / 1327 | 시간 244[s] | 퍼플렉서티 222.25\n",
      "| 에폭 1 |  반복 841 / 1327 | 시간 250[s] | 퍼플렉서티 229.95\n",
      "| 에폭 1 |  반복 861 / 1327 | 시간 256[s] | 퍼플렉서티 220.25\n",
      "| 에폭 1 |  반복 881 / 1327 | 시간 262[s] | 퍼플렉서티 205.23\n",
      "| 에폭 1 |  반복 901 / 1327 | 시간 267[s] | 퍼플렉서티 253.55\n",
      "| 에폭 1 |  반복 921 / 1327 | 시간 274[s] | 퍼플렉서티 228.60\n",
      "| 에폭 1 |  반복 941 / 1327 | 시간 280[s] | 퍼플렉서티 229.46\n",
      "| 에폭 1 |  반복 961 / 1327 | 시간 285[s] | 퍼플렉서티 244.49\n",
      "| 에폭 1 |  반복 981 / 1327 | 시간 291[s] | 퍼플렉서티 230.74\n",
      "| 에폭 1 |  반복 1001 / 1327 | 시간 298[s] | 퍼플렉서티 193.11\n",
      "| 에폭 1 |  반복 1021 / 1327 | 시간 303[s] | 퍼플렉서티 225.47\n",
      "| 에폭 1 |  반복 1041 / 1327 | 시간 309[s] | 퍼플렉서티 206.19\n",
      "| 에폭 1 |  반복 1061 / 1327 | 시간 315[s] | 퍼플렉서티 197.38\n",
      "| 에폭 1 |  반복 1081 / 1327 | 시간 321[s] | 퍼플렉서티 169.07\n",
      "| 에폭 1 |  반복 1101 / 1327 | 시간 327[s] | 퍼플렉서티 191.47\n",
      "| 에폭 1 |  반복 1121 / 1327 | 시간 333[s] | 퍼플렉서티 229.61\n",
      "| 에폭 1 |  반복 1141 / 1327 | 시간 338[s] | 퍼플렉서티 208.00\n",
      "| 에폭 1 |  반복 1161 / 1327 | 시간 344[s] | 퍼플렉서티 197.76\n",
      "| 에폭 1 |  반복 1181 / 1327 | 시간 349[s] | 퍼플렉서티 189.12\n",
      "| 에폭 1 |  반복 1201 / 1327 | 시간 355[s] | 퍼플렉서티 163.21\n",
      "| 에폭 1 |  반복 1221 / 1327 | 시간 361[s] | 퍼플렉서티 160.03\n",
      "| 에폭 1 |  반복 1241 / 1327 | 시간 367[s] | 퍼플렉서티 187.28\n",
      "| 에폭 1 |  반복 1261 / 1327 | 시간 373[s] | 퍼플렉서티 171.68\n",
      "| 에폭 1 |  반복 1281 / 1327 | 시간 379[s] | 퍼플렉서티 176.76\n",
      "| 에폭 1 |  반복 1301 / 1327 | 시간 384[s] | 퍼플렉서티 221.73\n",
      "| 에폭 1 |  반복 1321 / 1327 | 시간 390[s] | 퍼플렉서티 208.72\n",
      "| 에폭 2 |  반복 1 / 1327 | 시간 392[s] | 퍼플렉서티 224.56\n",
      "| 에폭 2 |  반복 21 / 1327 | 시간 399[s] | 퍼플렉서티 203.02\n",
      "| 에폭 2 |  반복 41 / 1327 | 시간 405[s] | 퍼플렉서티 188.67\n",
      "| 에폭 2 |  반복 61 / 1327 | 시간 411[s] | 퍼플렉서티 176.79\n",
      "| 에폭 2 |  반복 81 / 1327 | 시간 417[s] | 퍼플렉서티 159.19\n",
      "| 에폭 2 |  반복 101 / 1327 | 시간 423[s] | 퍼플렉서티 151.56\n",
      "| 에폭 2 |  반복 121 / 1327 | 시간 429[s] | 퍼플렉서티 160.02\n",
      "| 에폭 2 |  반복 141 / 1327 | 시간 435[s] | 퍼플렉서티 176.85\n",
      "| 에폭 2 |  반복 161 / 1327 | 시간 441[s] | 퍼플렉서티 191.98\n",
      "| 에폭 2 |  반복 181 / 1327 | 시간 447[s] | 퍼플렉서티 198.59\n",
      "| 에폭 2 |  반복 201 / 1327 | 시간 452[s] | 퍼플렉서티 185.59\n",
      "| 에폭 2 |  반복 221 / 1327 | 시간 458[s] | 퍼플렉서티 183.22\n",
      "| 에폭 2 |  반복 241 / 1327 | 시간 464[s] | 퍼플렉서티 175.39\n",
      "| 에폭 2 |  반복 261 / 1327 | 시간 470[s] | 퍼플렉서티 185.14\n",
      "| 에폭 2 |  반복 281 / 1327 | 시간 475[s] | 퍼플렉서티 185.08\n",
      "| 에폭 2 |  반복 301 / 1327 | 시간 481[s] | 퍼플렉서티 165.17\n",
      "| 에폭 2 |  반복 321 / 1327 | 시간 487[s] | 퍼플렉서티 137.45\n",
      "| 에폭 2 |  반복 341 / 1327 | 시간 492[s] | 퍼플렉서티 172.06\n",
      "| 에폭 2 |  반복 361 / 1327 | 시간 498[s] | 퍼플렉서티 197.01\n",
      "| 에폭 2 |  반복 381 / 1327 | 시간 504[s] | 퍼플렉서티 152.04\n",
      "| 에폭 2 |  반복 401 / 1327 | 시간 509[s] | 퍼플렉서티 168.42\n",
      "| 에폭 2 |  반복 421 / 1327 | 시간 515[s] | 퍼플렉서티 153.05\n",
      "| 에폭 2 |  반복 441 / 1327 | 시간 521[s] | 퍼플렉서티 162.15\n",
      "| 에폭 2 |  반복 461 / 1327 | 시간 526[s] | 퍼플렉서티 156.94\n",
      "| 에폭 2 |  반복 481 / 1327 | 시간 532[s] | 퍼플렉서티 156.01\n",
      "| 에폭 2 |  반복 501 / 1327 | 시간 538[s] | 퍼플렉서티 169.26\n",
      "| 에폭 2 |  반복 521 / 1327 | 시간 543[s] | 퍼플렉서티 174.37\n",
      "| 에폭 2 |  반복 541 / 1327 | 시간 549[s] | 퍼플렉서티 175.02\n",
      "| 에폭 2 |  반복 561 / 1327 | 시간 555[s] | 퍼플렉서티 153.88\n",
      "| 에폭 2 |  반복 581 / 1327 | 시간 560[s] | 퍼플렉서티 138.87\n",
      "| 에폭 2 |  반복 601 / 1327 | 시간 566[s] | 퍼플렉서티 188.16\n",
      "| 에폭 2 |  반복 621 / 1327 | 시간 572[s] | 퍼플렉서티 180.49\n",
      "| 에폭 2 |  반복 641 / 1327 | 시간 578[s] | 퍼플렉서티 164.59\n",
      "| 에폭 2 |  반복 661 / 1327 | 시간 584[s] | 퍼플렉서티 153.64\n",
      "| 에폭 2 |  반복 681 / 1327 | 시간 590[s] | 퍼플렉서티 128.85\n",
      "| 에폭 2 |  반복 701 / 1327 | 시간 595[s] | 퍼플렉서티 151.01\n",
      "| 에폭 2 |  반복 721 / 1327 | 시간 601[s] | 퍼플렉서티 159.68\n",
      "| 에폭 2 |  반복 741 / 1327 | 시간 607[s] | 퍼플렉서티 132.86\n",
      "| 에폭 2 |  반복 761 / 1327 | 시간 614[s] | 퍼플렉서티 128.51\n",
      "| 에폭 2 |  반복 781 / 1327 | 시간 620[s] | 퍼플렉서티 133.84\n",
      "| 에폭 2 |  반복 801 / 1327 | 시간 626[s] | 퍼플렉서티 146.79\n",
      "| 에폭 2 |  반복 821 / 1327 | 시간 632[s] | 퍼플렉서티 143.13\n",
      "| 에폭 2 |  반복 841 / 1327 | 시간 638[s] | 퍼플렉서티 143.64\n",
      "| 에폭 2 |  반복 861 / 1327 | 시간 644[s] | 퍼플렉서티 144.51\n",
      "| 에폭 2 |  반복 881 / 1327 | 시간 650[s] | 퍼플렉서티 129.32\n",
      "| 에폭 2 |  반복 901 / 1327 | 시간 656[s] | 퍼플렉서티 165.30\n",
      "| 에폭 2 |  반복 921 / 1327 | 시간 661[s] | 퍼플렉서티 147.08\n",
      "| 에폭 2 |  반복 941 / 1327 | 시간 667[s] | 퍼플렉서티 154.58\n",
      "| 에폭 2 |  반복 961 / 1327 | 시간 673[s] | 퍼플렉서티 164.45\n",
      "| 에폭 2 |  반복 981 / 1327 | 시간 678[s] | 퍼플렉서티 154.13\n",
      "| 에폭 2 |  반복 1001 / 1327 | 시간 684[s] | 퍼플렉서티 130.82\n",
      "| 에폭 2 |  반복 1021 / 1327 | 시간 690[s] | 퍼플렉서티 154.97\n",
      "| 에폭 2 |  반복 1041 / 1327 | 시간 696[s] | 퍼플렉서티 142.76\n",
      "| 에폭 2 |  반복 1061 / 1327 | 시간 702[s] | 퍼플렉서티 127.96\n",
      "| 에폭 2 |  반복 1081 / 1327 | 시간 707[s] | 퍼플렉서티 109.64\n",
      "| 에폭 2 |  반복 1101 / 1327 | 시간 713[s] | 퍼플렉서티 119.96\n",
      "| 에폭 2 |  반복 1121 / 1327 | 시간 720[s] | 퍼플렉서티 154.34\n",
      "| 에폭 2 |  반복 1141 / 1327 | 시간 725[s] | 퍼플렉서티 141.14\n",
      "| 에폭 2 |  반복 1161 / 1327 | 시간 731[s] | 퍼플렉서티 131.69\n",
      "| 에폭 2 |  반복 1181 / 1327 | 시간 737[s] | 퍼플렉서티 134.65\n",
      "| 에폭 2 |  반복 1201 / 1327 | 시간 743[s] | 퍼플렉서티 111.61\n",
      "| 에폭 2 |  반복 1221 / 1327 | 시간 749[s] | 퍼플렉서티 109.27\n",
      "| 에폭 2 |  반복 1241 / 1327 | 시간 755[s] | 퍼플렉서티 128.60\n",
      "| 에폭 2 |  반복 1261 / 1327 | 시간 761[s] | 퍼플렉서티 123.19\n",
      "| 에폭 2 |  반복 1281 / 1327 | 시간 767[s] | 퍼플렉서티 121.28\n",
      "| 에폭 2 |  반복 1301 / 1327 | 시간 772[s] | 퍼플렉서티 158.11\n",
      "| 에폭 2 |  반복 1321 / 1327 | 시간 778[s] | 퍼플렉서티 152.45\n",
      "| 에폭 3 |  반복 1 / 1327 | 시간 780[s] | 퍼플렉서티 162.71\n",
      "| 에폭 3 |  반복 21 / 1327 | 시간 786[s] | 퍼플렉서티 144.70\n",
      "| 에폭 3 |  반복 41 / 1327 | 시간 792[s] | 퍼플렉서티 134.49\n",
      "| 에폭 3 |  반복 61 / 1327 | 시간 797[s] | 퍼플렉서티 127.51\n",
      "| 에폭 3 |  반복 81 / 1327 | 시간 803[s] | 퍼플렉서티 117.34\n",
      "| 에폭 3 |  반복 101 / 1327 | 시간 809[s] | 퍼플렉서티 105.74\n",
      "| 에폭 3 |  반복 121 / 1327 | 시간 814[s] | 퍼플렉서티 116.44\n",
      "| 에폭 3 |  반복 141 / 1327 | 시간 820[s] | 퍼플렉서티 125.28\n",
      "| 에폭 3 |  반복 161 / 1327 | 시간 826[s] | 퍼플렉서티 141.46\n",
      "| 에폭 3 |  반복 181 / 1327 | 시간 832[s] | 퍼플렉서티 149.98\n",
      "| 에폭 3 |  반복 201 / 1327 | 시간 837[s] | 퍼플렉서티 142.24\n",
      "| 에폭 3 |  반복 221 / 1327 | 시간 843[s] | 퍼플렉서티 140.28\n",
      "| 에폭 3 |  반복 241 / 1327 | 시간 850[s] | 퍼플렉서티 133.38\n",
      "| 에폭 3 |  반복 261 / 1327 | 시간 856[s] | 퍼플렉서티 139.00\n",
      "| 에폭 3 |  반복 281 / 1327 | 시간 862[s] | 퍼플렉서티 139.81\n",
      "| 에폭 3 |  반복 301 / 1327 | 시간 868[s] | 퍼플렉서티 123.25\n",
      "| 에폭 3 |  반복 321 / 1327 | 시간 875[s] | 퍼플렉서티 102.30\n",
      "| 에폭 3 |  반복 341 / 1327 | 시간 881[s] | 퍼플렉서티 123.43\n",
      "| 에폭 3 |  반복 361 / 1327 | 시간 887[s] | 퍼플렉서티 151.99\n",
      "| 에폭 3 |  반복 381 / 1327 | 시간 892[s] | 퍼플렉서티 113.16\n",
      "| 에폭 3 |  반복 401 / 1327 | 시간 898[s] | 퍼플렉서티 129.86\n",
      "| 에폭 3 |  반복 421 / 1327 | 시간 904[s] | 퍼플렉서티 112.94\n",
      "| 에폭 3 |  반복 441 / 1327 | 시간 910[s] | 퍼플렉서티 123.84\n",
      "| 에폭 3 |  반복 461 / 1327 | 시간 915[s] | 퍼플렉서티 117.46\n",
      "| 에폭 3 |  반복 481 / 1327 | 시간 921[s] | 퍼플렉서티 119.33\n",
      "| 에폭 3 |  반복 501 / 1327 | 시간 927[s] | 퍼플렉서티 129.25\n",
      "| 에폭 3 |  반복 521 / 1327 | 시간 933[s] | 퍼플렉서티 137.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 3 |  반복 541 / 1327 | 시간 939[s] | 퍼플렉서티 136.03\n",
      "| 에폭 3 |  반복 561 / 1327 | 시간 945[s] | 퍼플렉서티 118.22\n",
      "| 에폭 3 |  반복 581 / 1327 | 시간 951[s] | 퍼플렉서티 105.03\n",
      "| 에폭 3 |  반복 601 / 1327 | 시간 957[s] | 퍼플렉서티 147.89\n",
      "| 에폭 3 |  반복 621 / 1327 | 시간 963[s] | 퍼플렉서티 142.26\n",
      "| 에폭 3 |  반복 641 / 1327 | 시간 969[s] | 퍼플렉서티 128.25\n",
      "| 에폭 3 |  반복 661 / 1327 | 시간 975[s] | 퍼플렉서티 121.56\n",
      "| 에폭 3 |  반복 681 / 1327 | 시간 981[s] | 퍼플렉서티 99.48\n",
      "| 에폭 3 |  반복 701 / 1327 | 시간 987[s] | 퍼플렉서티 119.33\n",
      "| 에폭 3 |  반복 721 / 1327 | 시간 993[s] | 퍼플렉서티 125.90\n",
      "| 에폭 3 |  반복 741 / 1327 | 시간 999[s] | 퍼플렉서티 106.95\n",
      "| 에폭 3 |  반복 761 / 1327 | 시간 1005[s] | 퍼플렉서티 102.01\n",
      "| 에폭 3 |  반복 781 / 1327 | 시간 1011[s] | 퍼플렉서티 102.99\n",
      "| 에폭 3 |  반복 801 / 1327 | 시간 1017[s] | 퍼플렉서티 114.97\n",
      "| 에폭 3 |  반복 821 / 1327 | 시간 1023[s] | 퍼플렉서티 116.02\n",
      "| 에폭 3 |  반복 841 / 1327 | 시간 1029[s] | 퍼플렉서티 114.29\n",
      "| 에폭 3 |  반복 861 / 1327 | 시간 1035[s] | 퍼플렉서티 120.35\n",
      "| 에폭 3 |  반복 881 / 1327 | 시간 1041[s] | 퍼플렉서티 105.49\n",
      "| 에폭 3 |  반복 901 / 1327 | 시간 1047[s] | 퍼플렉서티 131.87\n",
      "| 에폭 3 |  반복 921 / 1327 | 시간 1053[s] | 퍼플렉서티 119.32\n",
      "| 에폭 3 |  반복 941 / 1327 | 시간 1059[s] | 퍼플렉서티 128.15\n",
      "| 에폭 3 |  반복 961 / 1327 | 시간 1065[s] | 퍼플렉서티 132.33\n",
      "| 에폭 3 |  반복 981 / 1327 | 시간 1071[s] | 퍼플렉서티 124.11\n",
      "| 에폭 3 |  반복 1001 / 1327 | 시간 1076[s] | 퍼플렉서티 107.80\n",
      "| 에폭 3 |  반복 1021 / 1327 | 시간 1083[s] | 퍼플렉서티 127.87\n",
      "| 에폭 3 |  반복 1041 / 1327 | 시간 1089[s] | 퍼플렉서티 117.96\n",
      "| 에폭 3 |  반복 1061 / 1327 | 시간 1096[s] | 퍼플렉서티 102.66\n",
      "| 에폭 3 |  반복 1081 / 1327 | 시간 1103[s] | 퍼플렉서티 88.30\n",
      "| 에폭 3 |  반복 1101 / 1327 | 시간 1109[s] | 퍼플렉서티 94.71\n",
      "| 에폭 3 |  반복 1121 / 1327 | 시간 1115[s] | 퍼플렉서티 121.94\n",
      "| 에폭 3 |  반복 1141 / 1327 | 시간 1121[s] | 퍼플렉서티 113.22\n",
      "| 에폭 3 |  반복 1161 / 1327 | 시간 1127[s] | 퍼플렉서티 104.33\n",
      "| 에폭 3 |  반복 1181 / 1327 | 시간 1133[s] | 퍼플렉서티 111.13\n",
      "| 에폭 3 |  반복 1201 / 1327 | 시간 1139[s] | 퍼플렉서티 93.87\n",
      "| 에폭 3 |  반복 1221 / 1327 | 시간 1146[s] | 퍼플렉서티 88.74\n",
      "| 에폭 3 |  반복 1241 / 1327 | 시간 1153[s] | 퍼플렉서티 104.32\n",
      "| 에폭 3 |  반복 1261 / 1327 | 시간 1160[s] | 퍼플렉서티 104.00\n",
      "| 에폭 3 |  반복 1281 / 1327 | 시간 1166[s] | 퍼플렉서티 100.10\n",
      "| 에폭 3 |  반복 1301 / 1327 | 시간 1173[s] | 퍼플렉서티 129.56\n",
      "| 에폭 3 |  반복 1321 / 1327 | 시간 1179[s] | 퍼플렉서티 126.03\n",
      "| 에폭 4 |  반복 1 / 1327 | 시간 1181[s] | 퍼플렉서티 135.08\n",
      "| 에폭 4 |  반복 21 / 1327 | 시간 1188[s] | 퍼플렉서티 121.81\n",
      "| 에폭 4 |  반복 41 / 1327 | 시간 1194[s] | 퍼플렉서티 106.38\n",
      "| 에폭 4 |  반복 61 / 1327 | 시간 1200[s] | 퍼플렉서티 106.71\n",
      "| 에폭 4 |  반복 81 / 1327 | 시간 1207[s] | 퍼플렉서티 96.03\n",
      "| 에폭 4 |  반복 101 / 1327 | 시간 1213[s] | 퍼플렉서티 86.64\n",
      "| 에폭 4 |  반복 121 / 1327 | 시간 1219[s] | 퍼플렉서티 95.15\n",
      "| 에폭 4 |  반복 141 / 1327 | 시간 1225[s] | 퍼플렉서티 102.07\n",
      "| 에폭 4 |  반복 161 / 1327 | 시간 1232[s] | 퍼플렉서티 115.97\n",
      "| 에폭 4 |  반복 181 / 1327 | 시간 1238[s] | 퍼플렉서티 128.00\n",
      "| 에폭 4 |  반복 201 / 1327 | 시간 1245[s] | 퍼플렉서티 121.83\n",
      "| 에폭 4 |  반복 221 / 1327 | 시간 1252[s] | 퍼플렉서티 120.28\n",
      "| 에폭 4 |  반복 241 / 1327 | 시간 1258[s] | 퍼플렉서티 114.03\n",
      "| 에폭 4 |  반복 261 / 1327 | 시간 1265[s] | 퍼플렉서티 114.58\n",
      "| 에폭 4 |  반복 281 / 1327 | 시간 1271[s] | 퍼플렉서티 119.44\n",
      "| 에폭 4 |  반복 301 / 1327 | 시간 1277[s] | 퍼플렉서티 102.95\n",
      "| 에폭 4 |  반복 321 / 1327 | 시간 1283[s] | 퍼플렉서티 84.03\n",
      "| 에폭 4 |  반복 341 / 1327 | 시간 1289[s] | 퍼플렉서티 99.16\n",
      "| 에폭 4 |  반복 361 / 1327 | 시간 1295[s] | 퍼플렉서티 126.55\n",
      "| 에폭 4 |  반복 381 / 1327 | 시간 1302[s] | 퍼플렉서티 95.77\n",
      "| 에폭 4 |  반복 401 / 1327 | 시간 1308[s] | 퍼플렉서티 110.57\n",
      "| 에폭 4 |  반복 421 / 1327 | 시간 1314[s] | 퍼플렉서티 92.84\n",
      "| 에폭 4 |  반복 441 / 1327 | 시간 1321[s] | 퍼플렉서티 103.51\n",
      "| 에폭 4 |  반복 461 / 1327 | 시간 1327[s] | 퍼플렉서티 99.16\n",
      "| 에폭 4 |  반복 481 / 1327 | 시간 1334[s] | 퍼플렉서티 102.36\n",
      "| 에폭 4 |  반복 501 / 1327 | 시간 1341[s] | 퍼플렉서티 108.71\n",
      "| 에폭 4 |  반복 521 / 1327 | 시간 1347[s] | 퍼플렉서티 115.32\n",
      "| 에폭 4 |  반복 541 / 1327 | 시간 1354[s] | 퍼플렉서티 112.77\n",
      "| 에폭 4 |  반복 561 / 1327 | 시간 1361[s] | 퍼플렉서티 103.15\n",
      "| 에폭 4 |  반복 581 / 1327 | 시간 1367[s] | 퍼플렉서티 89.08\n",
      "| 에폭 4 |  반복 601 / 1327 | 시간 1374[s] | 퍼플렉서티 125.50\n",
      "| 에폭 4 |  반복 621 / 1327 | 시간 1380[s] | 퍼플렉서티 122.27\n",
      "| 에폭 4 |  반복 641 / 1327 | 시간 1387[s] | 퍼플렉서티 110.64\n",
      "| 에폭 4 |  반복 661 / 1327 | 시간 1394[s] | 퍼플렉서티 102.38\n",
      "| 에폭 4 |  반복 681 / 1327 | 시간 1401[s] | 퍼플렉서티 83.94\n",
      "| 에폭 4 |  반복 701 / 1327 | 시간 1408[s] | 퍼플렉서티 101.96\n",
      "| 에폭 4 |  반복 721 / 1327 | 시간 1416[s] | 퍼플렉서티 107.46\n",
      "| 에폭 4 |  반복 741 / 1327 | 시간 1423[s] | 퍼플렉서티 94.19\n",
      "| 에폭 4 |  반복 761 / 1327 | 시간 1430[s] | 퍼플렉서티 86.91\n",
      "| 에폭 4 |  반복 781 / 1327 | 시간 1436[s] | 퍼플렉서티 86.97\n",
      "| 에폭 4 |  반복 801 / 1327 | 시간 1443[s] | 퍼플렉서티 97.98\n",
      "| 에폭 4 |  반복 821 / 1327 | 시간 1449[s] | 퍼플렉서티 102.30\n",
      "| 에폭 4 |  반복 841 / 1327 | 시간 1456[s] | 퍼플렉서티 98.23\n",
      "| 에폭 4 |  반복 861 / 1327 | 시간 1462[s] | 퍼플렉서티 104.13\n",
      "| 에폭 4 |  반복 881 / 1327 | 시간 1469[s] | 퍼플렉서티 91.12\n",
      "| 에폭 4 |  반복 901 / 1327 | 시간 1476[s] | 퍼플렉서티 115.57\n",
      "| 에폭 4 |  반복 921 / 1327 | 시간 1483[s] | 퍼플렉서티 103.91\n",
      "| 에폭 4 |  반복 941 / 1327 | 시간 1491[s] | 퍼플렉서티 113.41\n",
      "| 에폭 4 |  반복 961 / 1327 | 시간 1498[s] | 퍼플렉서티 111.60\n",
      "| 에폭 4 |  반복 981 / 1327 | 시간 1505[s] | 퍼플렉서티 107.41\n",
      "| 에폭 4 |  반복 1001 / 1327 | 시간 1513[s] | 퍼플렉서티 95.78\n",
      "| 에폭 4 |  반복 1021 / 1327 | 시간 1520[s] | 퍼플렉서티 112.56\n",
      "| 에폭 4 |  반복 1041 / 1327 | 시간 1527[s] | 퍼플렉서티 103.16\n",
      "| 에폭 4 |  반복 1061 / 1327 | 시간 1534[s] | 퍼플렉서티 87.44\n",
      "| 에폭 4 |  반복 1081 / 1327 | 시간 1541[s] | 퍼플렉서티 78.11\n",
      "| 에폭 4 |  반복 1101 / 1327 | 시간 1547[s] | 퍼플렉서티 79.83\n",
      "| 에폭 4 |  반복 1121 / 1327 | 시간 1554[s] | 퍼플렉서티 102.25\n",
      "| 에폭 4 |  반복 1141 / 1327 | 시간 1561[s] | 퍼플렉서티 99.27\n",
      "| 에폭 4 |  반복 1161 / 1327 | 시간 1567[s] | 퍼플렉서티 90.47\n",
      "| 에폭 4 |  반복 1181 / 1327 | 시간 1574[s] | 퍼플렉서티 95.75\n",
      "| 에폭 4 |  반복 1201 / 1327 | 시간 1580[s] | 퍼플렉서티 83.14\n",
      "| 에폭 4 |  반복 1221 / 1327 | 시간 1586[s] | 퍼플렉서티 75.82\n",
      "| 에폭 4 |  반복 1241 / 1327 | 시간 1592[s] | 퍼플렉서티 90.27\n",
      "| 에폭 4 |  반복 1261 / 1327 | 시간 1598[s] | 퍼플렉서티 92.99\n",
      "| 에폭 4 |  반복 1281 / 1327 | 시간 1603[s] | 퍼플렉서티 88.33\n",
      "| 에폭 4 |  반복 1301 / 1327 | 시간 1609[s] | 퍼플렉서티 110.67\n",
      "| 에폭 4 |  반복 1321 / 1327 | 시간 1615[s] | 퍼플렉서티 109.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 48152 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 48373 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54140 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54540 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 47113 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 49436 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Users\\dud19\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 54000 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "퍼플렉서티 평가 중 ...\n",
      "234 / 235\n",
      "테스트 퍼플렉서티:  133.7511150464853\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 100\n",
    "hidden_size = 100  # RNN의 은닉 상태 벡터의 원소 수\n",
    "time_size = 35     # RNN을 펼치는 크기\n",
    "lr = 20.0\n",
    "max_epoch = 4\n",
    "max_grad = 0.25\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "# 모델 생성\n",
    "model = Rnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "# 기울기 클리핑을 적용하여 학습\n",
    "trainer.fit(xs, ts, max_epoch, batch_size, time_size, max_grad,\n",
    "            eval_interval=20)\n",
    "trainer.plot(ylim=(0, 500))\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "\n",
    "# 매개변수 저장\n",
    "model.save_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RNNLM 추가 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM 계층 다층화\n",
    "---\n",
    "<img src=img/fig6-29.png width='700'>  \n",
    "지금까지 우리는 LSTM 계층을 1층만 사용했지만 이를 2층, 3층으로 여러 겹 쌓으면 언어 모델의 정확도가 향상되리라 기대할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 드롭아웃에 의한 과적합 억제\n",
    "---\n",
    "층을 깊게 쌓음으로써 표현력이 풍부한 모델을 만들 수 있죠. 그러나 이런 모델은 종종 **과적합**<sup>overfitting</sup>을 일으킵니다.  \n",
    "과적합을 억제하는 전통적인 방법이 있습니다. '훈련 데이터의 양 늘리기'와 '모델의 복잡도 줄이기'가 있습니다.  \n",
    "그 외에는 모델의 복잡도에 페널티를 주는 **정규화**도 효과적입니다.  \n",
    "또, 드롭아웃 처럼 훈련 시 계층 내의 뉴런 몇개를 무작위로 무시하고 학습하는 방법도 일종의 정규화라고 할 수 있습니다.  \n",
    "<img src=img/fig6-30.png width='600'>  \n",
    "피드포워드 신경망에서는 드롭아웃 계층을 신경망의 진행방향에 삽입했습니다.  \n",
    "그러나 LSTM은 진행방향(시계열 방향)으로 삽입하면 학습 시 시간의 흐름에 따라 정보가 사라질 수 있습니다.\n",
    "따라서 드롭아웃 계층을 깊이 방향(상하 방향)으로 삽입하는 것이 좋습니다.\n",
    "<img src=img/fig6-32.png width='600'>  \n",
    "<img src=img/fig6-33.png width='600'>  \n",
    "이렇게 구성하면 시간 방향으로 아무리 진행해도 정보를 잃지 않습니다.  \n",
    "\n",
    "그런데 최근 연구에서는 RNN의 시간 방향 정규화를 목표로 하는 방법이 다양하게 제안되고 있습니다.  \n",
    "이 **변형 드롭아웃**<sup>Variational Dropout</sup>을 제안했고, 시간방향으로 적용하는 데 성공했습니다.  \n",
    "<img src=img/fig6-34.png width='600'>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치 공유\n",
    "---\n",
    "언어 모델을 개선하는 아주 간단한 트릭 중 **가중치 공유**<sup>weight tying</sup>가 있습니다.  \n",
    "그림에서 보듯 Embedding 계층과 Affine계층이 가중치를 공유합니다.  \n",
    "그러면 학습하는 매개변수 수가 크게 줄어드는 동시에 정확도도 향상되는 일석이조의 기술입니다.  \n",
    "매개변수 수가 줄어든다는 것은 학습하기가 쉬워지고, 과적합이 억제되는 혜택으로 이어집니다.  \n",
    "<img src=img/fig6-35.png width='600'>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개선된 RNNLM 구현\n",
    "---\n",
    "지금까지의 개선점 3가지를 사용하여 BetterRnnlm 클래스로 만들어 보겠습니다.  \n",
    "<img src=img/fig6-36.png width='400'>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m------------------------------------------------------------\u001b[0m\n",
      "                       \u001b[92mGPU Mode (cupy)\u001b[0m\n",
      "\u001b[92m------------------------------------------------------------\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import config\n",
    "config.GPU = True\n",
    "from common.time_layers import *\n",
    "from common.np import *  # import numpy as np\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    def __init__(self, vocab_size=10000, wordvec_size=650,\n",
    "                 hidden_size=650, dropout_ratio=0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "\n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4 * H).astype('f')\n",
    "        lstm_Wx2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4 * H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful=True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)  # weight tying!!\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "    def predict(self, xs, train_flg=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "\n",
    "    def forward(self, xs, ts, train_flg=True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 7[s] | 퍼플렉서티 10000.06\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 11[s] | 퍼플렉서티 4060.44\n",
      "| 에폭 1 |  반복 41 / 1327 | 시간 15[s] | 퍼플렉서티 1754.62\n",
      "| 에폭 1 |  반복 61 / 1327 | 시간 19[s] | 퍼플렉서티 1279.40\n",
      "| 에폭 1 |  반복 81 / 1327 | 시간 23[s] | 퍼플렉서티 1045.80\n",
      "| 에폭 1 |  반복 101 / 1327 | 시간 27[s] | 퍼플렉서티 856.59\n",
      "| 에폭 1 |  반복 121 / 1327 | 시간 31[s] | 퍼플렉서티 805.78\n",
      "| 에폭 1 |  반복 141 / 1327 | 시간 35[s] | 퍼플렉서티 727.72\n",
      "| 에폭 1 |  반복 161 / 1327 | 시간 39[s] | 퍼플렉서티 707.56\n",
      "| 에폭 1 |  반복 181 / 1327 | 시간 43[s] | 퍼플렉서티 670.35\n",
      "| 에폭 1 |  반복 201 / 1327 | 시간 47[s] | 퍼플렉서티 594.43\n",
      "| 에폭 1 |  반복 221 / 1327 | 시간 52[s] | 퍼플렉서티 577.43\n",
      "| 에폭 1 |  반복 241 / 1327 | 시간 56[s] | 퍼플렉서티 519.34\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1572e9a4d3ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n\u001b[1;32m---> 42\u001b[1;33m                 time_size=time_size, max_grad=max_grad)\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-scratch-2-Study\\common\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;31m# 기울기를 구해 매개변수 갱신\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-9b2eca0dd2af>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-scratch-2-Study\\common\\time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dhs)\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdhs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m             \u001b[0mdxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Deep-Learning-from-scratch-2-Study\\common\\time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dh_next, dc_next)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mtanh_c_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_next\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdc_next\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdh_next\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtanh_c_next\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mdc_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import config\n",
    "config.GPU = True\n",
    "from common.optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity, to_gpu\n",
    "from dataset import ptb\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "# 학습 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "if config.GPU:\n",
    "    corpus = to_gpu(corpus)\n",
    "    corpus_val = to_gpu(corpus_val)\n",
    "    corpus_test = to_gpu(corpus_test)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n",
    "                time_size=time_size, max_grad=max_grad)\n",
    "\n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티: ', ppl)\n",
    "\n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "\n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "# 테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(model, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습은 너무 오래걸려서 생략..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
